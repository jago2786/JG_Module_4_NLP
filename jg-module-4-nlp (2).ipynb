{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import linear_model, model_selection, preprocessing\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nimport keras\nfrom keras import layers\nfrom keras.utils import pad_sequences\n#from keras.preprocessing.text import Tokenizer\nimport matplotlib.pyplot as plt\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-04T19:51:02.221809Z","iopub.execute_input":"2025-03-04T19:51:02.222198Z","iopub.status.idle":"2025-03-04T19:51:18.216889Z","shell.execute_reply.started":"2025-03-04T19:51:02.222164Z","shell.execute_reply":"2025-03-04T19:51:18.215950Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"1. This dataset contains tweets, which are binarily classified to being about a real natural disaster or not.","metadata":{}},{"cell_type":"code","source":"#Load train and test datasets\ntrain_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nprint(train_df)\nprint(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T20:32:42.967504Z","iopub.execute_input":"2025-03-04T20:32:42.968008Z","iopub.status.idle":"2025-03-04T20:32:43.023762Z","shell.execute_reply.started":"2025-03-04T20:32:42.967960Z","shell.execute_reply":"2025-03-04T20:32:43.022365Z"}},"outputs":[{"name":"stdout","text":"         id keyword location  \\\n0         1     NaN      NaN   \n1         4     NaN      NaN   \n2         5     NaN      NaN   \n3         6     NaN      NaN   \n4         7     NaN      NaN   \n...     ...     ...      ...   \n7608  10869     NaN      NaN   \n7609  10870     NaN      NaN   \n7610  10871     NaN      NaN   \n7611  10872     NaN      NaN   \n7612  10873     NaN      NaN   \n\n                                                   text  target  \n0     Our Deeds are the Reason of this #earthquake M...       1  \n1                Forest fire near La Ronge Sask. Canada       1  \n2     All residents asked to 'shelter in place' are ...       1  \n3     13,000 people receive #wildfires evacuation or...       1  \n4     Just got sent this photo from Ruby #Alaska as ...       1  \n...                                                 ...     ...  \n7608  Two giant cranes holding a bridge collapse int...       1  \n7609  @aria_ahrary @TheTawniest The out of control w...       1  \n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n7611  Police investigating after an e-bike collided ...       1  \n7612  The Latest: More Homes Razed by Northern Calif...       1  \n\n[7613 rows x 5 columns]\n         id keyword location  \\\n0         0     NaN      NaN   \n1         2     NaN      NaN   \n2         3     NaN      NaN   \n3         9     NaN      NaN   \n4        11     NaN      NaN   \n...     ...     ...      ...   \n3258  10861     NaN      NaN   \n3259  10865     NaN      NaN   \n3260  10868     NaN      NaN   \n3261  10874     NaN      NaN   \n3262  10875     NaN      NaN   \n\n                                                   text  \n0                    Just happened a terrible car crash  \n1     Heard about #earthquake is different cities, s...  \n2     there is a forest fire at spot pond, geese are...  \n3              Apocalypse lighting. #Spokane #wildfires  \n4         Typhoon Soudelor kills 28 in China and Taiwan  \n...                                                 ...  \n3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n3259  Storm in RI worse than last hurricane. My city...  \n3260  Green Line derailment in Chicago http://t.co/U...  \n3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n3262  #CityofCalgary has activated its Municipal Eme...  \n\n[3263 rows x 4 columns]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"The dataset has id, keyword, location and text, with 7612 tweets in train with 3262 tweets in test. keyword and location do not appear to be used, but it will need to be removed when submitting the test dataset prediction.","metadata":{}},{"cell_type":"code","source":"#count_vectorizer = feature_extraction.text.CountVectorizer()\n\nmax_words = 30000\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(train_df[\"text\"])\n\n#train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n#print(tokenizer.shape)\n#train_vectors_3D = np.zeros((train_vectors.shape[0],1,train_vectors.shape[1]))\n#print(train_vectors_3D.shape)\ntrain_vectors = tokenizer.texts_to_sequences(train_df[\"text\"])\n#for i in range(train_vectors_3D.shape[0]):\n#    for j in range(train_vectors_3D.shape[2]):\n#        train_vectors_3D[i,0,j] = train_vectors[i,j]\n#train_vectors_modified = [train_vectors, None]\n#for i in range(train_vectors.shape[0]):\n#    train_vectors_modified[i] = train_vectors[i]\n\ntest_vectors = tokenizer.texts_to_sequences(test_df[\"text\"])\n#test_vectors = count_vectorizer.transform(test_df[\"text\"])\n#test_vectors_3D = np.zeros((test_vectors.shape[0],1,test_vectors.shape[1]))\n#print(test_vectors_3D.shape)\n#for i in range(test_vectors_3D.shape[0]):\n#    for j in range(test_vectors_3D.shape[2]):\n#        test_vectors_3D[i,0,j] = test_vectors[i,j]\n#test_vectors = test_vectors.reshape(test_vectors.shape[0], 1, test_vectors.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T19:52:45.812972Z","iopub.execute_input":"2025-03-04T19:52:45.813404Z","iopub.status.idle":"2025-03-04T19:52:46.204858Z","shell.execute_reply.started":"2025-03-04T19:52:45.813371Z","shell.execute_reply":"2025-03-04T19:52:46.204035Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"2. In order to properly assess, all sequences must be padded to the same length. To do so, we will first see what the longest sequence in test_vectors is.","metadata":{}},{"cell_type":"code","source":"max_len = 0\nmin_len = 100\nfor i in range(len(train_vectors)):\n    max_len = max(np.size(train_vectors[i]),max_len)\n    min_len = min(np.size(train_vectors[i]),min_len)\n#print(np.size(train_vectors))\nprint('Max sequence length = ' + str(max_len))\nprint('Min sequence length = ' + str(min_len))\n#print(train_vectors.shape)\n#print(train_vectors[0].todense())\n\n#print(train_vectors_modified.todense().shape)\n#print(train_vectors_modified.shape)\n#print(train_vectors_modified[0].todense())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T20:35:57.544833Z","iopub.execute_input":"2025-03-04T20:35:57.545261Z","iopub.status.idle":"2025-03-04T20:35:57.601025Z","shell.execute_reply.started":"2025-03-04T20:35:57.545229Z","shell.execute_reply":"2025-03-04T20:35:57.600211Z"}},"outputs":[{"name":"stdout","text":"Max sequence length = 33\nMin sequence length = 1\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Now that max_sequence length has been determined to be 33, we will pad each sequence to have a length of 33. None of the datasets contaon 0 words, so all of the can be included.","metadata":{}},{"cell_type":"code","source":"train_padded = pad_sequences(train_vectors, maxlen=max_len)\ntest_padded = pad_sequences(test_vectors, maxlen=max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T19:52:55.136206Z","iopub.execute_input":"2025-03-04T19:52:55.136550Z","iopub.status.idle":"2025-03-04T19:52:55.179697Z","shell.execute_reply.started":"2025-03-04T19:52:55.136526Z","shell.execute_reply":"2025-03-04T19:52:55.178783Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"I will go through SimpleRNN, LSTM, and GRU over ~50 epochs to see if validation loss hits a minimum. Based on the behavior, I may mess with the number of epochs, learning weight, or batch size to attempt to improve the model. Once I determine what the best val_loss is, I will use that model to predict test images.","metadata":{}},{"cell_type":"code","source":"#Built using guide from https://www.tensorflow.org/guide/keras/working_with_rnns\nmodel_SimpleRNN = keras.Sequential()\n#model_SimpleRNN = keras.Sequential([layers.Embedding(input_dim=21637, output_dim = 64), layers.SimpleRNN(7613, return_sequences=True), layers.Dense(1)])\nmodel_SimpleRNN.add(layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\nmodel_SimpleRNN.add(layers.SimpleRNN(64))\nmodel_SimpleRNN.add(layers.Dense(1, activation='sigmoid'))\n#model.add(layers.Embedding(input_dim=21637))\n\n#np.reshape(train_vectors, (train_vectors[0], 1, train_vectors.shape[1]))\n\nmodel_SimpleRNN.summary()\nmodel_SimpleRNN.compile(loss=keras.losses.binary_crossentropy, optimizer='sgd',metrics=['accuracy'])\ny_true_train = train_df['target']\n#y_true_train_resize = []\n#for i in range(len(y_true_train)):\n#    y_true_train_resize.append([1, y_true_train])\nmodel_SimpleRNN.fit(x=train_padded, y = train_df['target'], epochs=50, batch_size = 128, validation_split = 0.25, shuffle=True, callbacks=tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/SimpleRNN_{epoch:02d}-{val_loss:.2f}.keras'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T19:53:17.817572Z","iopub.execute_input":"2025-03-04T19:53:17.817898Z","iopub.status.idle":"2025-03-04T19:53:56.982232Z","shell.execute_reply.started":"2025-03-04T19:53:17.817875Z","shell.execute_reply":"2025-03-04T19:53:56.981311Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5160 - loss: 0.6939 - val_accuracy: 0.5525 - val_loss: 0.6833\nEpoch 2/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5739 - loss: 0.6745 - val_accuracy: 0.5604 - val_loss: 0.6722\nEpoch 3/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5849 - loss: 0.6680 - val_accuracy: 0.5683 - val_loss: 0.6652\nEpoch 4/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5990 - loss: 0.6611 - val_accuracy: 0.5793 - val_loss: 0.6593\nEpoch 5/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6055 - loss: 0.6557 - val_accuracy: 0.6523 - val_loss: 0.6460\nEpoch 6/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6315 - loss: 0.6468 - val_accuracy: 0.6476 - val_loss: 0.6418\nEpoch 7/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6239 - loss: 0.6491 - val_accuracy: 0.6623 - val_loss: 0.6353\nEpoch 8/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6296 - loss: 0.6431 - val_accuracy: 0.6460 - val_loss: 0.6358\nEpoch 9/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6277 - loss: 0.6427 - val_accuracy: 0.6213 - val_loss: 0.6426\nEpoch 10/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6418 - loss: 0.6348 - val_accuracy: 0.6455 - val_loss: 0.6356\nEpoch 11/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6406 - loss: 0.6318 - val_accuracy: 0.6534 - val_loss: 0.6321\nEpoch 12/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6487 - loss: 0.6354 - val_accuracy: 0.6607 - val_loss: 0.6292\nEpoch 13/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6530 - loss: 0.6277 - val_accuracy: 0.5951 - val_loss: 0.6575\nEpoch 14/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6547 - loss: 0.6281 - val_accuracy: 0.6796 - val_loss: 0.6151\nEpoch 15/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6573 - loss: 0.6224 - val_accuracy: 0.6786 - val_loss: 0.6078\nEpoch 16/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6643 - loss: 0.6184 - val_accuracy: 0.6192 - val_loss: 0.6512\nEpoch 17/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6720 - loss: 0.6099 - val_accuracy: 0.6754 - val_loss: 0.6138\nEpoch 18/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6888 - loss: 0.5994 - val_accuracy: 0.6565 - val_loss: 0.6129\nEpoch 19/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6840 - loss: 0.6011 - val_accuracy: 0.6880 - val_loss: 0.6046\nEpoch 20/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6919 - loss: 0.6010 - val_accuracy: 0.6822 - val_loss: 0.6103\nEpoch 21/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7038 - loss: 0.5878 - val_accuracy: 0.7054 - val_loss: 0.5873\nEpoch 22/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6931 - loss: 0.5883 - val_accuracy: 0.6602 - val_loss: 0.6224\nEpoch 23/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6945 - loss: 0.5857 - val_accuracy: 0.6675 - val_loss: 0.6148\nEpoch 24/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6984 - loss: 0.5851 - val_accuracy: 0.7033 - val_loss: 0.5944\nEpoch 25/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7210 - loss: 0.5686 - val_accuracy: 0.6807 - val_loss: 0.6125\nEpoch 26/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7149 - loss: 0.5704 - val_accuracy: 0.7122 - val_loss: 0.5839\nEpoch 27/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6843 - loss: 0.5949 - val_accuracy: 0.6959 - val_loss: 0.5861\nEpoch 28/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7299 - loss: 0.5488 - val_accuracy: 0.5909 - val_loss: 0.6812\nEpoch 29/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7120 - loss: 0.5605 - val_accuracy: 0.7085 - val_loss: 0.5780\nEpoch 30/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7335 - loss: 0.5534 - val_accuracy: 0.7059 - val_loss: 0.5923\nEpoch 31/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7416 - loss: 0.5440 - val_accuracy: 0.6896 - val_loss: 0.5960\nEpoch 32/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7413 - loss: 0.5416 - val_accuracy: 0.7017 - val_loss: 0.5867\nEpoch 33/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7559 - loss: 0.5256 - val_accuracy: 0.6907 - val_loss: 0.6098\nEpoch 34/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7643 - loss: 0.5108 - val_accuracy: 0.4517 - val_loss: 1.1164\nEpoch 35/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6786 - loss: 0.6660 - val_accuracy: 0.7048 - val_loss: 0.5902\nEpoch 36/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7759 - loss: 0.5008 - val_accuracy: 0.6292 - val_loss: 0.6639\nEpoch 37/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7774 - loss: 0.4991 - val_accuracy: 0.6949 - val_loss: 0.5864\nEpoch 38/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7780 - loss: 0.4882 - val_accuracy: 0.6770 - val_loss: 0.6443\nEpoch 39/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7600 - loss: 0.5040 - val_accuracy: 0.6996 - val_loss: 0.5826\nEpoch 40/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7921 - loss: 0.4644 - val_accuracy: 0.7038 - val_loss: 0.5837\nEpoch 41/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7737 - loss: 0.4892 - val_accuracy: 0.6833 - val_loss: 0.6147\nEpoch 42/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7816 - loss: 0.4818 - val_accuracy: 0.6933 - val_loss: 0.5974\nEpoch 43/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7701 - loss: 0.4920 - val_accuracy: 0.6912 - val_loss: 0.6028\nEpoch 44/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8178 - loss: 0.4480 - val_accuracy: 0.5572 - val_loss: 0.7449\nEpoch 45/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7862 - loss: 0.4795 - val_accuracy: 0.7111 - val_loss: 0.5867\nEpoch 46/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8186 - loss: 0.4201 - val_accuracy: 0.6471 - val_loss: 0.6677\nEpoch 47/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7486 - loss: 0.5657 - val_accuracy: 0.7232 - val_loss: 0.5759\nEpoch 48/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8206 - loss: 0.4138 - val_accuracy: 0.6954 - val_loss: 0.6035\nEpoch 49/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8229 - loss: 0.4168 - val_accuracy: 0.6822 - val_loss: 0.6349\nEpoch 50/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8339 - loss: 0.3949 - val_accuracy: 0.6859 - val_loss: 0.6266\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ab0177b8a90>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"It is shown that the validation loss flucuates after 12 epochs, so I will schedule learning rate to attempt to stabalize it after 12 epochs.","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch, lr):\n    if epoch < 12:\n        return lr\n    else:\n        return lr*np.exp(-0.1*(epoch-7))\n\ncallback = keras.callbacks.LearningRateScheduler(scheduler)\n\nmodel_SimpleRNN_lrs = keras.Sequential()\n#model_SimpleRNN = keras.Sequential([layers.Embedding(input_dim=21637, output_dim = 64), layers.SimpleRNN(7613, return_sequences=True), layers.Dense(1)])\nmodel_SimpleRNN_lrs.add(layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\nmodel_SimpleRNN_lrs.add(layers.SimpleRNN(64))\nmodel_SimpleRNN_lrs.add(layers.Dense(1, activation='sigmoid'))\n#model.add(layers.Embedding(input_dim=21637))\n\n#np.reshape(train_vectors, (train_vectors[0], 1, train_vectors.shape[1]))\n\nmodel_SimpleRNN_lrs.summary()\nmodel_SimpleRNN_lrs.compile(loss=keras.losses.binary_crossentropy, optimizer='sgd',metrics=['accuracy'])\ny_true_train = train_df['target']\n#y_true_train_resize = []\n#for i in range(len(y_true_train)):\n#    y_true_train_resize.append([1, y_true_train])\nmodel_SimpleRNN_lrs.fit(x=train_padded, y = train_df['target'], epochs=50, batch_size = 128, validation_split = 0.25, callbacks=[callback], shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T19:54:58.555521Z","iopub.execute_input":"2025-03-04T19:54:58.555979Z","iopub.status.idle":"2025-03-04T19:55:35.691514Z","shell.execute_reply.started":"2025-03-04T19:54:58.555946Z","shell.execute_reply":"2025-03-04T19:55:35.690393Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5697 - loss: 0.6821 - val_accuracy: 0.5457 - val_loss: 0.6774 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5818 - loss: 0.6675 - val_accuracy: 0.6077 - val_loss: 0.6619 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5985 - loss: 0.6620 - val_accuracy: 0.6203 - val_loss: 0.6529 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6192 - loss: 0.6515 - val_accuracy: 0.5951 - val_loss: 0.6539 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6259 - loss: 0.6478 - val_accuracy: 0.6507 - val_loss: 0.6401 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6301 - loss: 0.6468 - val_accuracy: 0.6534 - val_loss: 0.6358 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6318 - loss: 0.6443 - val_accuracy: 0.6696 - val_loss: 0.6308 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6384 - loss: 0.6386 - val_accuracy: 0.6555 - val_loss: 0.6295 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6453 - loss: 0.6329 - val_accuracy: 0.6770 - val_loss: 0.6234 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6603 - loss: 0.6270 - val_accuracy: 0.6875 - val_loss: 0.6188 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6654 - loss: 0.6185 - val_accuracy: 0.6780 - val_loss: 0.6164 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6795 - loss: 0.6082 - val_accuracy: 0.6928 - val_loss: 0.6057 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6819 - loss: 0.6028 - val_accuracy: 0.6859 - val_loss: 0.6085 - learning_rate: 0.0061\nEpoch 14/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7015 - loss: 0.5874 - val_accuracy: 0.6912 - val_loss: 0.6034 - learning_rate: 0.0033\nEpoch 15/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7059 - loss: 0.5848 - val_accuracy: 0.7001 - val_loss: 0.5950 - learning_rate: 0.0017\nEpoch 16/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7008 - loss: 0.5833 - val_accuracy: 0.7017 - val_loss: 0.5945 - learning_rate: 7.4274e-04\nEpoch 17/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7100 - loss: 0.5778 - val_accuracy: 0.6901 - val_loss: 0.5997 - learning_rate: 3.0197e-04\nEpoch 18/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7060 - loss: 0.5813 - val_accuracy: 0.6917 - val_loss: 0.5975 - learning_rate: 1.1109e-04\nEpoch 19/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7072 - loss: 0.5835 - val_accuracy: 0.6954 - val_loss: 0.5968 - learning_rate: 3.6979e-05\nEpoch 20/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7058 - loss: 0.5800 - val_accuracy: 0.6959 - val_loss: 0.5967 - learning_rate: 1.1138e-05\nEpoch 21/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7175 - loss: 0.5761 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 3.0354e-06\nEpoch 22/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7024 - loss: 0.5858 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 7.4852e-07\nEpoch 23/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7140 - loss: 0.5749 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.6702e-07\nEpoch 24/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7134 - loss: 0.5773 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 3.3720e-08\nEpoch 25/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7124 - loss: 0.5774 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 6.1601e-09\nEpoch 26/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7102 - loss: 0.5815 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.0183e-09\nEpoch 27/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7138 - loss: 0.5714 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.5230e-10\nEpoch 28/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7126 - loss: 0.5776 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 2.0612e-11\nEpoch 29/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7027 - loss: 0.5841 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 2.5240e-12\nEpoch 30/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7136 - loss: 0.5708 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 2.7967e-13\nEpoch 31/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7099 - loss: 0.5768 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 2.8039e-14\nEpoch 32/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7146 - loss: 0.5761 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 2.5437e-15\nEpoch 33/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7202 - loss: 0.5727 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 2.0880e-16\nEpoch 34/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7070 - loss: 0.5805 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.5508e-17\nEpoch 35/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7097 - loss: 0.5751 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.0422e-18\nEpoch 36/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7143 - loss: 0.5728 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 6.3378e-20\nEpoch 37/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7118 - loss: 0.5762 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 3.4873e-21\nEpoch 38/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7022 - loss: 0.5843 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.7362e-22\nEpoch 39/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7146 - loss: 0.5781 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 7.8215e-24\nEpoch 40/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7129 - loss: 0.5800 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 3.1882e-25\nEpoch 41/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7044 - loss: 0.5777 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.1759e-26\nEpoch 42/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6994 - loss: 0.5844 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 3.9244e-28\nEpoch 43/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7004 - loss: 0.5894 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.1851e-29\nEpoch 44/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6988 - loss: 0.5867 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 3.2380e-31\nEpoch 45/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7125 - loss: 0.5781 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 8.0056e-33\nEpoch 46/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7130 - loss: 0.5750 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.7909e-34\nEpoch 47/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7138 - loss: 0.5731 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 3.6251e-36\nEpoch 48/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7122 - loss: 0.5778 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 6.6397e-38\nEpoch 49/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7131 - loss: 0.5773 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.1004e-39\nEpoch 50/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7068 - loss: 0.5861 - val_accuracy: 0.6959 - val_loss: 0.5966 - learning_rate: 1.6500e-41\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ab017852a40>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"It appears the validation accuracy becomes steady around 30 epochs, but training is short so we'll continue to train 50 epochs. I will now test LSTM and GRU methods against simple RNN.","metadata":{}},{"cell_type":"code","source":"#LSTM Model\nmodel_LSTM_lrs = keras.Sequential()\n#model_SimpleRNN = keras.Sequential([layers.Embedding(input_dim=21637, output_dim = 64), layers.SimpleRNN(7613, return_sequences=True), layers.Dense(1)])\nmodel_LSTM_lrs.add(layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\nmodel_LSTM_lrs.add(layers.LSTM(64))\nmodel_LSTM_lrs.add(layers.Dense(1, activation='sigmoid'))\n#model.add(layers.Embedding(input_dim=21637))\n\n#np.reshape(train_vectors, (train_vectors[0], 1, train_vectors.shape[1]))\n\nmodel_LSTM_lrs.summary()\nmodel_LSTM_lrs.compile(loss=keras.losses.binary_crossentropy, optimizer='adam',metrics=['accuracy'])\ny_true_train = train_df['target']\n#y_true_train_resize = []\n#for i in range(len(y_true_train)):\n#    y_true_train_resize.append([1, y_true_train])\nmodel_LSTM_lrs.fit(x=train_padded, y = train_df['target'], epochs=50, batch_size = 128, validation_split = 0.25, callbacks=[callback], shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T19:55:57.541979Z","iopub.execute_input":"2025-03-04T19:55:57.542440Z","iopub.status.idle":"2025-03-04T19:57:52.215139Z","shell.execute_reply.started":"2025-03-04T19:55:57.542406Z","shell.execute_reply":"2025-03-04T19:57:52.213966Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.5766 - loss: 0.6693 - val_accuracy: 0.7227 - val_loss: 0.5823 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7799 - loss: 0.4849 - val_accuracy: 0.7857 - val_loss: 0.4574 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9143 - loss: 0.2441 - val_accuracy: 0.7742 - val_loss: 0.4954 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9509 - loss: 0.1480 - val_accuracy: 0.7663 - val_loss: 0.5833 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9705 - loss: 0.0900 - val_accuracy: 0.7568 - val_loss: 0.6203 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9811 - loss: 0.0554 - val_accuracy: 0.7311 - val_loss: 0.6903 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9870 - loss: 0.0433 - val_accuracy: 0.7479 - val_loss: 0.7523 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9924 - loss: 0.0292 - val_accuracy: 0.7405 - val_loss: 0.8179 - learning_rate: 0.0010\nEpoch 9/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9949 - loss: 0.0219 - val_accuracy: 0.7400 - val_loss: 0.8071 - learning_rate: 0.0010\nEpoch 10/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9919 - loss: 0.0251 - val_accuracy: 0.7300 - val_loss: 0.9652 - learning_rate: 0.0010\nEpoch 11/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9949 - loss: 0.0175 - val_accuracy: 0.7532 - val_loss: 0.8281 - learning_rate: 0.0010\nEpoch 12/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9941 - loss: 0.0183 - val_accuracy: 0.7463 - val_loss: 1.0578 - learning_rate: 0.0010\nEpoch 13/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9939 - loss: 0.0157 - val_accuracy: 0.7479 - val_loss: 1.0458 - learning_rate: 6.0653e-04\nEpoch 14/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9947 - loss: 0.0149 - val_accuracy: 0.7489 - val_loss: 1.0162 - learning_rate: 3.3287e-04\nEpoch 15/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9967 - loss: 0.0097 - val_accuracy: 0.7416 - val_loss: 1.0458 - learning_rate: 1.6530e-04\nEpoch 16/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9961 - loss: 0.0103 - val_accuracy: 0.7411 - val_loss: 1.0666 - learning_rate: 7.4274e-05\nEpoch 17/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9967 - loss: 0.0085 - val_accuracy: 0.7400 - val_loss: 1.0759 - learning_rate: 3.0197e-05\nEpoch 18/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9945 - loss: 0.0105 - val_accuracy: 0.7400 - val_loss: 1.0791 - learning_rate: 1.1109e-05\nEpoch 19/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.7405 - val_loss: 1.0803 - learning_rate: 3.6979e-06\nEpoch 20/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9948 - loss: 0.0122 - val_accuracy: 0.7405 - val_loss: 1.0807 - learning_rate: 1.1138e-06\nEpoch 21/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9965 - loss: 0.0084 - val_accuracy: 0.7405 - val_loss: 1.0808 - learning_rate: 3.0354e-07\nEpoch 22/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9960 - loss: 0.0089 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 7.4852e-08\nEpoch 23/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9947 - loss: 0.0103 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.6702e-08\nEpoch 24/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9957 - loss: 0.0096 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 3.3720e-09\nEpoch 25/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9958 - loss: 0.0107 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 6.1601e-10\nEpoch 26/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9968 - loss: 0.0088 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.0183e-10\nEpoch 27/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9961 - loss: 0.0099 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.5230e-11\nEpoch 28/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9950 - loss: 0.0106 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 2.0612e-12\nEpoch 29/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9946 - loss: 0.0111 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 2.5240e-13\nEpoch 30/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9960 - loss: 0.0100 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 2.7967e-14\nEpoch 31/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9958 - loss: 0.0102 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 2.8039e-15\nEpoch 32/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 2.5437e-16\nEpoch 33/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 2.0880e-17\nEpoch 34/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9953 - loss: 0.0104 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.5508e-18\nEpoch 35/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.0422e-19\nEpoch 36/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9964 - loss: 0.0094 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 6.3378e-21\nEpoch 37/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9954 - loss: 0.0106 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 3.4873e-22\nEpoch 38/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9952 - loss: 0.0104 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.7362e-23\nEpoch 39/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9951 - loss: 0.0100 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 7.8215e-25\nEpoch 40/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 3.1882e-26\nEpoch 41/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9957 - loss: 0.0098 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.1759e-27\nEpoch 42/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9958 - loss: 0.0084 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 3.9244e-29\nEpoch 43/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9961 - loss: 0.0090 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.1851e-30\nEpoch 44/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9952 - loss: 0.0105 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 3.2380e-32\nEpoch 45/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 8.0056e-34\nEpoch 46/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9967 - loss: 0.0084 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.7909e-35\nEpoch 47/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9948 - loss: 0.0116 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 3.6251e-37\nEpoch 48/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9964 - loss: 0.0083 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 6.6397e-39\nEpoch 49/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9969 - loss: 0.0082 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.1004e-40\nEpoch 50/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9958 - loss: 0.0093 - val_accuracy: 0.7405 - val_loss: 1.0809 - learning_rate: 1.6507e-42\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7aaffe5bb7f0>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"LSTM validation loss was minimized after 3 epochs, so I will train it to only 3 epochs","metadata":{}},{"cell_type":"code","source":"#LSTM Model\nmodel_LSTM_lrs = keras.Sequential()\n#model_SimpleRNN = keras.Sequential([layers.Embedding(input_dim=21637, output_dim = 64), layers.SimpleRNN(7613, return_sequences=True), layers.Dense(1)])\nmodel_LSTM_lrs.add(layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\nmodel_LSTM_lrs.add(layers.LSTM(64))\nmodel_LSTM_lrs.add(layers.Dense(1, activation='sigmoid'))\n#model.add(layers.Embedding(input_dim=21637))\n\n#np.reshape(train_vectors, (train_vectors[0], 1, train_vectors.shape[1]))\n\nmodel_LSTM_lrs.summary()\nmodel_LSTM_lrs.compile(loss=keras.losses.binary_crossentropy, optimizer='adam',metrics=['accuracy'])\ny_true_train = train_df['target']\n#y_true_train_resize = []\n#for i in range(len(y_true_train)):\n#    y_true_train_resize.append([1, y_true_train])\nmodel_LSTM_lrs.fit(x=train_padded, y = train_df['target'], epochs=3, batch_size = 128, validation_split = 0.25, callbacks=[callback], shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T20:02:38.901944Z","iopub.execute_input":"2025-03-04T20:02:38.902338Z","iopub.status.idle":"2025-03-04T20:02:48.097522Z","shell.execute_reply.started":"2025-03-04T20:02:38.902308Z","shell.execute_reply":"2025-03-04T20:02:48.096515Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_6\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/3\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.5825 - loss: 0.6667 - val_accuracy: 0.7279 - val_loss: 0.5724 - learning_rate: 0.0010\nEpoch 2/3\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7944 - loss: 0.4730 - val_accuracy: 0.7784 - val_loss: 0.4614 - learning_rate: 0.0010\nEpoch 3/3\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9049 - loss: 0.2569 - val_accuracy: 0.7726 - val_loss: 0.5008 - learning_rate: 0.0010\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7aaff4657370>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"This method has a smaller val_loss. I will now train on a GRU and compare it to this result","metadata":{}},{"cell_type":"code","source":"#GRU  Model\nmodel_GRU = keras.Sequential()\n#model_SimpleRNN = keras.Sequential([layers.Embedding(input_dim=21637, output_dim = 64), layers.SimpleRNN(7613, return_sequences=True), layers.Dense(1)])\nmodel_GRU.add(layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\nmodel_GRU.add(layers.GRU(64, recurrent_dropout=0.2))\nmodel_GRU.add(layers.Dense(1, activation='sigmoid'))\n#model.add(layers.Embedding(input_dim=21637))\n\n#np.reshape(train_vectors, (train_vectors[0], 1, train_vectors.shape[1]))\n\nmodel_GRU.summary()\nmodel_GRU.compile(loss=keras.losses.binary_crossentropy, optimizer='adam',metrics=['accuracy'])\ny_true_train = train_df['target']\n#y_true_train_resize = []\n#for i in range(len(y_true_train)):\n#    y_true_train_resize.append([1, y_true_train])\nmodel_GRU.fit(x=train_padded, y = train_df['target'], epochs=50, batch_size = 128, validation_split = 0.25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T20:03:42.011948Z","iopub.execute_input":"2025-03-04T20:03:42.012379Z","iopub.status.idle":"2025-03-04T20:05:37.660773Z","shell.execute_reply.started":"2025-03-04T20:03:42.012348Z","shell.execute_reply":"2025-03-04T20:05:37.659737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.5890 - loss: 0.6692 - val_accuracy: 0.7001 - val_loss: 0.6070\nEpoch 2/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7739 - loss: 0.4990 - val_accuracy: 0.7285 - val_loss: 0.5563\nEpoch 3/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9037 - loss: 0.2703 - val_accuracy: 0.7269 - val_loss: 0.5485\nEpoch 4/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9506 - loss: 0.1419 - val_accuracy: 0.7274 - val_loss: 0.5630\nEpoch 5/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9778 - loss: 0.0755 - val_accuracy: 0.7195 - val_loss: 0.5935\nEpoch 6/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9860 - loss: 0.0437 - val_accuracy: 0.7022 - val_loss: 0.6536\nEpoch 7/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9893 - loss: 0.0382 - val_accuracy: 0.7027 - val_loss: 0.6609\nEpoch 8/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9927 - loss: 0.0269 - val_accuracy: 0.7033 - val_loss: 0.6885\nEpoch 9/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9938 - loss: 0.0207 - val_accuracy: 0.6959 - val_loss: 0.6794\nEpoch 10/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9931 - loss: 0.0306 - val_accuracy: 0.7043 - val_loss: 0.7495\nEpoch 11/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9929 - loss: 0.0180 - val_accuracy: 0.7080 - val_loss: 0.7299\nEpoch 12/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9954 - loss: 0.0218 - val_accuracy: 0.7048 - val_loss: 0.7590\nEpoch 13/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9925 - loss: 0.0163 - val_accuracy: 0.7012 - val_loss: 0.7601\nEpoch 14/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9945 - loss: 0.0143 - val_accuracy: 0.7006 - val_loss: 0.7668\nEpoch 15/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9946 - loss: 0.0168 - val_accuracy: 0.6928 - val_loss: 0.7505\nEpoch 16/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9955 - loss: 0.0155 - val_accuracy: 0.6959 - val_loss: 0.7529\nEpoch 17/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9935 - loss: 0.0166 - val_accuracy: 0.7101 - val_loss: 0.8005\nEpoch 18/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 0.6959 - val_loss: 0.7511\nEpoch 19/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9907 - loss: 0.0309 - val_accuracy: 0.6912 - val_loss: 0.7947\nEpoch 20/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9936 - loss: 0.0165 - val_accuracy: 0.6780 - val_loss: 0.8492\nEpoch 21/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9960 - loss: 0.0108 - val_accuracy: 0.7006 - val_loss: 0.8337\nEpoch 22/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9936 - loss: 0.0128 - val_accuracy: 0.6922 - val_loss: 0.8418\nEpoch 23/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9950 - loss: 0.0126 - val_accuracy: 0.6922 - val_loss: 0.8214\nEpoch 24/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9935 - loss: 0.0123 - val_accuracy: 0.6954 - val_loss: 0.8281\nEpoch 25/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9947 - loss: 0.0110 - val_accuracy: 0.6970 - val_loss: 0.8482\nEpoch 26/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9953 - loss: 0.0108 - val_accuracy: 0.6891 - val_loss: 0.8400\nEpoch 27/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9958 - loss: 0.0096 - val_accuracy: 0.7096 - val_loss: 0.8495\nEpoch 28/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9942 - loss: 0.0117 - val_accuracy: 0.7043 - val_loss: 0.8495\nEpoch 29/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9952 - loss: 0.0117 - val_accuracy: 0.7048 - val_loss: 0.8639\nEpoch 30/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9964 - loss: 0.0092 - val_accuracy: 0.6996 - val_loss: 0.8544\nEpoch 31/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9954 - loss: 0.0097 - val_accuracy: 0.6938 - val_loss: 0.8733\nEpoch 32/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9945 - loss: 0.0104 - val_accuracy: 0.7059 - val_loss: 0.8669\nEpoch 33/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9946 - loss: 0.0096 - val_accuracy: 0.7054 - val_loss: 0.8761\nEpoch 34/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9953 - loss: 0.0102 - val_accuracy: 0.7027 - val_loss: 0.8566\nEpoch 35/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9953 - loss: 0.0101 - val_accuracy: 0.7022 - val_loss: 0.8622\nEpoch 36/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9950 - loss: 0.0106 - val_accuracy: 0.6770 - val_loss: 0.8292\nEpoch 37/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9911 - loss: 0.0229 - val_accuracy: 0.6775 - val_loss: 0.8099\nEpoch 38/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9905 - loss: 0.0312 - val_accuracy: 0.6791 - val_loss: 0.9052\nEpoch 39/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.9935 - loss: 0.0129 - val_accuracy: 0.6717 - val_loss: 0.9156\nEpoch 40/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9950 - loss: 0.0157 - val_accuracy: 0.6471 - val_loss: 0.8328\nEpoch 41/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9889 - loss: 0.0298 - val_accuracy: 0.6744 - val_loss: 0.8730\nEpoch 42/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9951 - loss: 0.0121 - val_accuracy: 0.6791 - val_loss: 0.8878\nEpoch 43/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9959 - loss: 0.0085 - val_accuracy: 0.6765 - val_loss: 0.9077\nEpoch 44/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9949 - loss: 0.0101 - val_accuracy: 0.6812 - val_loss: 0.9093\nEpoch 45/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9969 - loss: 0.0070 - val_accuracy: 0.6759 - val_loss: 0.9188\nEpoch 46/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9945 - loss: 0.0158 - val_accuracy: 0.6854 - val_loss: 0.9027\nEpoch 47/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9950 - loss: 0.0097 - val_accuracy: 0.6901 - val_loss: 0.8986\nEpoch 48/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9964 - loss: 0.0075 - val_accuracy: 0.6843 - val_loss: 0.9040\nEpoch 49/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9966 - loss: 0.0072 - val_accuracy: 0.6801 - val_loss: 0.9078\nEpoch 50/50\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9951 - loss: 0.0108 - val_accuracy: 0.6780 - val_loss: 0.8964\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7aaff4b1fcd0>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"Since GRU val_loss also increased, I will set epochs to 3 like the LSTM model.","metadata":{}},{"cell_type":"code","source":"#GRU  Model\nmodel_GRU = keras.Sequential()\n#model_SimpleRNN = keras.Sequential([layers.Embedding(input_dim=21637, output_dim = 64), layers.SimpleRNN(7613, return_sequences=True), layers.Dense(1)])\nmodel_GRU.add(layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\nmodel_GRU.add(layers.GRU(64, recurrent_dropout=0.2))\nmodel_GRU.add(layers.Dense(1, activation='sigmoid'))\n#model.add(layers.Embedding(input_dim=21637))\n\n#np.reshape(train_vectors, (train_vectors[0], 1, train_vectors.shape[1]))\n\nmodel_GRU.summary()\nmodel_GRU.compile(loss=keras.losses.binary_crossentropy, optimizer='adam',metrics=['accuracy'])\ny_true_train = train_df['target']\n#y_true_train_resize = []\n#for i in range(len(y_true_train)):\n#    y_true_train_resize.append([1, y_true_train])\nmodel_GRU.fit(x=train_padded, y = train_df['target'], epochs=3, batch_size = 64, validation_split = 0.25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T20:08:23.534302Z","iopub.execute_input":"2025-03-04T20:08:23.534707Z","iopub.status.idle":"2025-03-04T20:08:36.244588Z","shell.execute_reply.started":"2025-03-04T20:08:23.534675Z","shell.execute_reply":"2025-03-04T20:08:36.243420Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_9\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/3\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.6007 - loss: 0.6608 - val_accuracy: 0.7442 - val_loss: 0.5768\nEpoch 2/3\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8493 - loss: 0.3759 - val_accuracy: 0.7500 - val_loss: 0.5294\nEpoch 3/3\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9385 - loss: 0.1825 - val_accuracy: 0.7227 - val_loss: 0.5659\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7aafbec55270>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"In terms of val_loss, GRU outperforms simpleRNN but not as well as the LSTM model. I will therefore use LSTM to predict the test dataset.","metadata":{}},{"cell_type":"code","source":"y_pred = model_LSTM_lrs.predict(test_padded)\n\ntest_df['y_pred'] = (y_pred >= 0.5).astype(int)\nprint(test_df.head())\n\ntest_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T20:13:02.983335Z","iopub.execute_input":"2025-03-04T20:13:02.983738Z","iopub.status.idle":"2025-03-04T20:13:04.290346Z","shell.execute_reply.started":"2025-03-04T20:13:02.983708Z","shell.execute_reply":"2025-03-04T20:13:04.289238Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n   id keyword location                                               text  \\\n0   0     NaN      NaN                 Just happened a terrible car crash   \n1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n\n   y_pred  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"![image.png](attachment:0b3b31ec-339f-4020-812b-dc3e830e394e.png)","metadata":{},"attachments":{"0b3b31ec-339f-4020-812b-dc3e830e394e.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"The test dataset was approximatly as accurate as the validation dataset was.\n\nOne of the interesting things about this project is that I did try reducing batch_size to increase accuracy, but it actually had an inverse effect on val_accuracy. I believe the model was overfitting on the training dataset, and therefore did not have the effect I thought it would.","metadata":{}}]}